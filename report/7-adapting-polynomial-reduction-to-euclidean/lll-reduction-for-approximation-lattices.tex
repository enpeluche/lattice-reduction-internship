
\section{Vers une réduction LLL adaptée aux réseaux d’approximation}

On va donner une définition équivalente du réseau d'approximation \( (F, \sigma) \) mais adaptée pour les réseaux euclidiens.

\begin{definition}
    Soit \( F \in M_n (\Z) \), un degré de précision \( \sigma \in \N\), et \(p \in \N\). On définit
    \[
        F_{p^\sigma} \coloneqq  \{ v \in \Z^n | vF = 0 \mod p^\sigma \}
    \]
\end{definition}

Contrairement au cas polynomial, la situation est ici fondamentalement différente. Nous verrons par la suite s’il est nécessaire d’imposer des restrictions sur \( p \) et \( \sigma \), et le cas échéant, lesquelles.

\begin{proposition}
    \( F_{p^\sigma} \) est un réseau euclidien de dimension \( n \).
\end{proposition}

\begin{remark}
    \( F_{p^\sigma} \) est un réseau \( p^\sigma\)-aire.
\end{remark}

Comment peut-on calculer une base de \( F_{p^\sigma} \)~? Est-il possible d’en extraire une base \( \mathrm{LLL} \)-réduite, et ce, de manière efficace~? Comme dans le cas polynomial traité pour le réseau \( (F, \sigma) \), il est d'abord nécessaire de calculer une décomposition \footnote{Il s’agit d’une généralisation de la décomposition \( P L F = U \), où \( U \) était une matrice triangulaire supérieure. Ici, on relâche cette contrainte en ne demandant que \( U \) soit échelonnée par lignes.} de la forme

\begin{equation}
    \underbrace{
        \begin{bmatrix}
            e_{\tau(1)} \\
            \vdots      \\
            e_{\tau(n)}
        \end{bmatrix}
    }_{P}
    \cdot
    \underbrace{
        \begin{bmatrix}
            L_r & 0       \\
            G   & I_{m-r}
        \end{bmatrix}
    }_{L}
    \cdot
    F
    =
    \underbrace{
        \begin{bmatrix}
            E' \\
            0
        \end{bmatrix}
    }_{E}
\end{equation}

où \(r \coloneqq \rang(F) \), \( P \) est une matrice de permutation, \( L \) est une matrice triangulaire inférieure et \( E \) est échelonnée en ligne.


\begin{smallalgo}{\textsc{PLE}$(A)$}{algo:ple}
    \KwIn{$A \in \mathbb{K}^{n \times m}$}
    \KwOut{Matrices \( P \), \( L \), \( E \) telles que \( 6.1 \) est satisfaite.}

    $n \gets \text{nrows}(A)$,\quad $m \gets \text{ncols}(A)$\;
    $P \gets I_n$, \quad $L \gets I_n$, \quad $E \gets A$\;

    \Pour{$i \gets 0$ \KwTo $m{-}1$}{
        $(\text{pivot}, i_{\text{pivot}}) \gets \textsc{Pivot}(E_{*,i}, \{i, \dots, n{-}1\})$\;

        \Si{$\text{pivot} = \texttt{None}$}{
            \textbf{continuer}
        }

        \Si{$i_{\text{pivot}} \neq i$}{
            Échanger les lignes $i$ et $i_{\text{pivot}}$ dans $P$ et $E$\;

            \Pour{$k \gets 0$ \KwTo $i{-}1$}{
                Échanger $L[i,k]$ et $L[i_{\text{pivot}},k]$\;
            }
        }

        \Pour{$j \gets i{+}1$ \KwTo $n{-}1$}{
            $s \gets E[j,i] / \text{pivot}$\;
            \Si{$s \neq 0$}{
                $E \gets E$ avec ligne $j$ \textbf{moins} $s$ fois ligne $i$\;
                $L \gets L$ avec ligne $j$ \textbf{moins} $s$ fois ligne $i$\;
            }
        }
    }

    \KwRet{$(P, L, E)$}
\end{smallalgo}

\begin{remark}

    Comme c'est vrai pour toute permutations, il serait intéressant de choisir certaines permutations particulières, notamment qui ordonne les vecteurs par norme croissante.

\end{remark}

\begin{remark}
    J'ai mis trop d'investissement dans cet algorithme, j'en ai fais plusieurs versions, allant d'une version naïve où je calculais tous les pivots pour ordonner les lignes de façon à avoir les mineurs principaux inversibles, à une stratégie plus subtile d'échange quand nécessaire, grâce aux conseils avisés de mon encadrant. Cet algorithme fonctionne sur \( \Z_p \) pour \( p \) premier, car les pivots sont inversibles, je réfléchissais à une stratégie pour rendre cet algorithme fonctionnel  sur \( \Z_n \).
\end{remark}

\begin{theoreme}
    L'algorithme \textsc{PLE} calcule correctement une décomposition qui satisfait 6.1.
\end{theoreme}

\begin{counterexample}[Limite de l’algorithme \textsc{PLE}]
    L’algorithme \textsc{PLE} ne s’applique pas dans tous les cas.

    Soit
    \[
        A =
        \begin{bmatrix}
            3 & 4 \\
            4 & 3
        \end{bmatrix}
        \in M_2(\mathbb{Z}/12\mathbb{Z}).
    \]
    Dans cet anneau, les coefficients \( 3 \) et \( 4 \) ne sont pas inversibles, ce qui empêche de procéder aux opérations de pivot nécessaires.\\

    Ce contre-exemple montre que la validité de l’algorithme repose sur une hypothèse cruciale : \emph{les pivots doivent être inversibles}.
\end{counterexample}



\begin{example}
    \[ \displaystyle
        \underbrace{\begin{pmatrix}
                1            & 0            & 0 & 0 \\
                -\frac{3}{4} & 1            & 0 & 0 \\
                -\frac{1}{2} & 0            & 1 & 0 \\
                0            & -\frac{1}{3} & 0 & 1
            \end{pmatrix}}_{L}
        \x
        \underbrace{
            \begin{pmatrix}
                1 & 0 & 0 & 0 \\
                0 & 0 & 1 & 0 \\
                0 & 1 & 0 & 0 \\
                0 & 0 & 0 & 1
            \end{pmatrix}
        }_{P}
        \underbrace{\begin{pmatrix}
                4 & 2 & 4 & 2 \\
                2 & 1 & 2 & 1 \\
                3 & 3 & 3 & 3 \\
                1 & 1 & 1 & 1
            \end{pmatrix}}_{F}
        =
        \underbrace{\begin{pmatrix}
                4 & 2           & 4 & 2           \\
                0 & \frac{3}{2} & 0 & \frac{3}{2} \\
                0 & 0           & 0 & 0           \\
                0 & 0           & 0 & 0
            \end{pmatrix}}_{E}
    \]
\end{example}


On en déduit donc un algorithme pour calculer une base.


De 6.1 on déduit que

\[
    \begin{bmatrix}
        e_{\tau(1)} \\
        \vdots      \\
        e_{\tau(n)}
    \end{bmatrix}
    \cdot
    \begin{bmatrix}
        L_r \cdot p^\sigma & 0       \\
        G                  & I_{m-r}
    \end{bmatrix}
    \cdot
    F
    =
    \begin{bmatrix}
        E' \cdot p^\sigma \\
        0
    \end{bmatrix}
    =
    \begin{bmatrix}
        0 \\
        0
    \end{bmatrix}
    \mod p^\sigma
\]

\begin{theoreme}
    Les matrices
    \[
        \begin{bmatrix}
            L_r \cdot p^\sigma & 0       \\
            G                  & I_{m-r}
        \end{bmatrix}
        \cdot
        \begin{bmatrix}
            e_{\tau(1)} \\
            \vdots      \\
            e_{\tau(n)}
        \end{bmatrix}
        , \quad
        \begin{bmatrix}
            I_r \cdot p^\sigma & 0       \\
            G                  & I_{m-r}
        \end{bmatrix}
        \cdot
        \begin{bmatrix}
            e_{\tau(1)} \\
            \vdots      \\
            e_{\tau(n)}
        \end{bmatrix}
    \]
    sont deux bases de \( F_{p^\sigma}\)
\end{theoreme}

\begin{remark}
    Il vaut mieux privilégier la seconde base car les \(r\) premières lignes sont orthonormées, ce qui nous permet de déduire intuitivement que la base sera de meilleure qualité.
\end{remark}
%CA MARCHE QUE QUAND SIGMA VAUT 1
\begin{smallalgo}{\textsc{Basis}$(F, p, \texttt{mode})$}{algo:basis_modes}
    \KwIn{Une matrice \( F \in \mathbb{K}[x]^{m \times n} \), un scalaire \( p \in \mathbb{K} \), et une chaîne \texttt{mode} égale à \texttt{v1} ou \texttt{v2}}
    \KwOut{Une base transformée selon le mode choisi}

    $G \gets \text{copie}(F)$\;
    $(P, L, E) \gets \textsc{PLE}(G)$\;
    $r \gets \text{rang}(F)$\;

    \Si{\texttt{mode} = \texttt{v1}}{
        \Pour{$i \gets 0$ \KwTo $r{-}1$}{
            Multiplier la ligne $i$ de $L$ par $p$\;
        }
    }

    \Si{\texttt{mode} = \texttt{v2}}{
        \Pour{$i \gets 0$ \KwTo $r{-}1$}{
            Remplacer la ligne $i$ de $L$ par $p \cdot e_i$\;
            \tcp*{$e_i$ : $i$-ème vecteur de la base canonique}
        }
    }

    \KwRet{$L \cdot P$}
\end{smallalgo}


\begin{example}

    En partant de la matrice
    \(
    F =
    \begin{pmatrix}
        4 & 2 & 4 & 2 \\
        2 & 1 & 2 & 1 \\
        3 & 3 & 3 & 3 \\
        1 & 1 & 1 & 1
    \end{pmatrix}
    \)

    On peut calculer une base de \( F_{5^4}\)

    \[
        \begin{pmatrix}
            625          & 0 & 0            & 0 \\
            -\frac{1}{2} & 1 & 0            & 0 \\
            0            & 0 & 625          & 0 \\
            0            & 0 & -\frac{1}{3} & 1
        \end{pmatrix}
    \]
\end{example}

On peut donc maintenant définir un algorithme sur un principe diviser pour régner.
\begin{smallalgo}{\textsc{LLL-DAC-Padique}$(F, p, \sigma)$}{algo:lll_dac_padic}
    \KwIn{$F \in \mathbb{K}^{m \times n}$, un entier premier $p$, un entier $\sigma \geq 1$}
    \KwOut{Une base "LLL-réduite?" en précision $p^\sigma$}

    \Si{$\sigma = 1$}{
        \KwRet{$\textsc{LLL}(\textsc{ApproximantBasis}(F, p))$}
    }

    $\tau \gets \left\lfloor \dfrac{\sigma + 1}{2} \right\rfloor$\;

    $V_1 \gets \textsc{LLL-DAC-Padique}(F, p, \tau)$ \tcp*[r]{Appel récursif sur demi-précision}

    $F_{\text{low}} \gets \dfrac{V_1 \cdot F}{p^\tau}$ \tcp*[r]{Mise à jour du problème}

    $V_2 \gets \textsc{LLL-DAC-Padique}(F_{\text{low}}, p, \sigma - \tau)$ \tcp*[r]{Appel récursif décalé}

    \KwRet{$V_2 \cdot V_1$}
\end{smallalgo}

Similairement à la preuve du chapitre précédent, \(V_2 V_1\) est une base de \( F_{p^\sigma} \).

\begin{problem}[\textbf{Question}]
Dans quelle mesure le produit de matrices LLL-réduites reste-t-il lui-même LLL-réduit ? Peut-on quantifier cette propriété ?
\end{problem}

Si \( V_1 \) est une matrice orthogonale, c'est-à-dire dont les lignes sont orthonormées, alors \( V_2 V_1\) est \( \mathrm{LLL}\)-réduite.

On rappelle que \( V_1 = U_1 V_1^* \) d'après le procédé de Gram-Schmidt. En écrivant \( V_1 V_2 = V_1 V_2^* ((V_2^*)^{-1} U_2 V_2^*) \), peut-être pourront nous mieux contrôler le résultat du produit.